---
title: "Weather"
author: "Varun Vasudeva"
date: "10/19/2020"
output: html_document
---

# Weather Classification Neural Network

This model was built to preempt, based on a simple table of given weather conditions, whether the day would be rainy or snowy. It demonstrates the efficiency of deep learning on large datasets with many recordings. The benefit of a model like this is that this classification required no data that a sensor-equipped small weather station can't provide.

Data: https://www.kaggle.com/budincsevity/szeged-weather

```{r libraries}
library(tensorflow)
library(keras)
library(reticulate)
library(tidyverse)
library(caret)

use_condaenv("r-reticulate")
use_backend("plaidml")
```

```{r data load}
weather <- read.csv("weatherHistory.csv")
head(weather)
```
Below, we remove unnecessary data such as `Summary`, `Daily.Summary`, and `Loud.Cover`. Since we are only concerned with creating a model that can accurately classify whether the day will feature rain or snow, and not with creating any visual time-series plots, the `Formatted.Date` data is also unnecessary.

```{r data mutation}
weather <- weather %>%
  select(!(Formatted.Date|Summary|Daily.Summary|Loud.Cover)) %>%
  rename(precip = Precip.Type, temp = Temperature..C., atemp = Apparent.Temperature..C., humidity = Humidity, windspeed = Wind.Speed..km.h., windbearing = Wind.Bearing..degrees., visibility = Visibility..km., pressure = Pressure..millibars.) %>%
  filter(precip == "rain" | precip == "snow") %>%
  mutate(precip = as.factor(precip)) %>%
  drop_na()

head(weather)
```
Then, we create a split the data into train, validation, and test subsets. The training set constitutes 60% of the entire data, the validation 20%, and the test also 20%. We one-hot encode the labels for all three sets in order to be able to feed it into the model. 

```{r data split}
train_prop <- 0.60
val_prop <- 0.20
test_prop <- 0.20

train_size <- floor(train_prop * nrow(weather))
val_size <- floor(val_prop * nrow(weather))
test_size <- floor(test_prop * nrow(weather))

train_indices <- sort(sample(seq_len(nrow(weather)), size = train_size))
temp <- setdiff(seq_len(nrow(weather)), train_indices)
val_indices <- sort(sample(temp, size = val_size))
test_indices <- setdiff(temp, val_indices)

train <- weather[train_indices, ]
validation <- weather[val_indices, ]
test <- weather[test_indices, ]

train_data <- select(train, !precip)
train_labels <- select(train, precip)
val_data <- select(validation, !precip)
val_labels <- select(validation, precip)
test_data <- select(test, !precip)
test_labels <- select(test, precip)

train_data <- data.matrix(train_data)
train_labels <- data.matrix(train_labels)
val_data <- data.matrix(val_data)
val_labels <- data.matrix(val_labels)
test_data <- data.matrix(test_data)
test_labels <- data.matrix(test_labels)

train_labels <- to_categorical(train_labels)
val_labels <- to_categorical(val_labels)
test_labels <- to_categorical(test_labels)
```

We include a small sanity check here to ensure that our data is in the correct number of dimensions and of the same order before using it as an input for the neural network.

```{r dim test}
dim(train_data)
dim(train_labels)
dim(val_data)
dim(val_labels)
dim(test_data)
dim(test_labels)

head(train_data)
head(train_labels)
```

The model itself is a multi-layer perceptron with 227,219 trainable parameters. It has 5 dense layers: the first four utilize the ReLu and Sigmoid activation functions and the fifth layer consists of only 3 units and utilizes a Softmax activation in order to classify rain or snow.

```{r model}
network <- keras_model_sequential() %>%
  layer_dense(units = 512, activation = 'relu', input_shape = c(7)) %>%
  layer_dense(units = 256, activation = 'relu') %>%
  layer_dense(units = 256, activation = 'sigmoid') %>%
  layer_dense(units = 100, activation = 'relu') %>%
  layer_dense(units = 3, activation = 'softmax')

network %>% compile(
  optimizer = 'rmsprop',
  loss = 'categorical_crossentropy',
  metrics = c('accuracy')
)

network
```

```{r model fit/test}
history <- network %>% 
  fit(train_data, train_labels, epochs = 10, verbose = 2, validation_data = list(val_data, val_labels))
metrics <- network %>% 
  evaluate(test_data, test_labels)
```

We can see that the model achieves a weather prediction accuracy of over 99% using basic measurements of air and weather characteristics. While it is certainly not the level of weather updates we expect now, the use of neural networks will be interesting to see in fields that are yet to adopt deep learning techniques.

```{r model evaluation}
plot(history)
metrics
```